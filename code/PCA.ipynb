{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PCA to test different modeling approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Principal Component Analysis?\n",
    "I'll try to dumb it down as much as I can but for the most part:\n",
    "<br>PCA is reducing the dimensionality of your data set to make it easier to model. Pretty much you're turning your features (temp, wind speed, etc...) into components\n",
    "<br>For example, let's say you have a painting that's mixed with a whole bunch of colors. What if you wanted to recreate that painting but you only have money to buy a few colors?\n",
    "<br>PCA breaks down that painting into the core colors (components). This will let you recreate that picture with the limited amount of colors you have.\n",
    "<br>Now in turn this will reduce how closely your painting looks to the original but if you use more components, the more it'll look like the original.\n",
    "<br>So what we're trying to do is break down our dataset and make it easier to use. Instead of having those features like temp, wind speed, etc..., we'll have pc1, pc2, and so on\n",
    "<br>Each principal component will explain less and less of the variance in data, so pc1 does the most and so on\n",
    "<br><br>What does that mean for us?\n",
    "<br>I comment as I code but pretty much, we have 11 features which isn't bad compared to the other groups but we could reduce it more if we changed them to principal components\n",
    "<br>As you'll see later we dont get the luxury of only using 2 components because our data is very varied so we'll end up using 9 to get 90% of variance.\n",
    "<br>That isn't really much but doing 8000x9 is still easier than 8000x11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Functioning Day</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Winter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>1003</td>\n",
       "      <td>19</td>\n",
       "      <td>4.2</td>\n",
       "      <td>34</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>764</td>\n",
       "      <td>20</td>\n",
       "      <td>3.4</td>\n",
       "      <td>37</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>694</td>\n",
       "      <td>21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>39</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>712</td>\n",
       "      <td>22</td>\n",
       "      <td>2.1</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>584</td>\n",
       "      <td>23</td>\n",
       "      <td>1.9</td>\n",
       "      <td>43</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rented Bike Count  Hour  Temperature(C)  Humidity(%)  \\\n",
       "Date                                                               \n",
       "2017-12-01                254     0            -5.2           37   \n",
       "2017-12-01                204     1            -5.5           38   \n",
       "2017-12-01                173     2            -6.0           39   \n",
       "2017-12-01                107     3            -6.2           40   \n",
       "2017-12-01                 78     4            -6.0           36   \n",
       "...                       ...   ...             ...          ...   \n",
       "2018-11-30               1003    19             4.2           34   \n",
       "2018-11-30                764    20             3.4           37   \n",
       "2018-11-30                694    21             2.6           39   \n",
       "2018-11-30                712    22             2.1           41   \n",
       "2018-11-30                584    23             1.9           43   \n",
       "\n",
       "            Wind speed (m/s)  Visibility (10m)  Solar Radiation (MJ/m2)  \\\n",
       "Date                                                                      \n",
       "2017-12-01               2.2              2000                      0.0   \n",
       "2017-12-01               0.8              2000                      0.0   \n",
       "2017-12-01               1.0              2000                      0.0   \n",
       "2017-12-01               0.9              2000                      0.0   \n",
       "2017-12-01               2.3              2000                      0.0   \n",
       "...                      ...               ...                      ...   \n",
       "2018-11-30               2.6              1894                      0.0   \n",
       "2018-11-30               2.3              2000                      0.0   \n",
       "2018-11-30               0.3              1968                      0.0   \n",
       "2018-11-30               1.0              1859                      0.0   \n",
       "2018-11-30               1.3              1909                      0.0   \n",
       "\n",
       "            Rainfall(mm)  Snowfall (cm)  Functioning Day  Spring  Summer  \\\n",
       "Date                                                                       \n",
       "2017-12-01           0.0            0.0                1       0       0   \n",
       "2017-12-01           0.0            0.0                1       0       0   \n",
       "2017-12-01           0.0            0.0                1       0       0   \n",
       "2017-12-01           0.0            0.0                1       0       0   \n",
       "2017-12-01           0.0            0.0                1       0       0   \n",
       "...                  ...            ...              ...     ...     ...   \n",
       "2018-11-30           0.0            0.0                1       0       0   \n",
       "2018-11-30           0.0            0.0                1       0       0   \n",
       "2018-11-30           0.0            0.0                1       0       0   \n",
       "2018-11-30           0.0            0.0                1       0       0   \n",
       "2018-11-30           0.0            0.0                1       0       0   \n",
       "\n",
       "            Winter  \n",
       "Date                \n",
       "2017-12-01       1  \n",
       "2017-12-01       1  \n",
       "2017-12-01       1  \n",
       "2017-12-01       1  \n",
       "2017-12-01       1  \n",
       "...            ...  \n",
       "2018-11-30       0  \n",
       "2018-11-30       0  \n",
       "2018-11-30       0  \n",
       "2018-11-30       0  \n",
       "2018-11-30       0  \n",
       "\n",
       "[8760 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.model_selection import train_test_split # for training a model\n",
    "from sklearn.metrics import mean_squared_error, r2_score # for finding r2 and MSE\n",
    "\n",
    "path = '../data/bike.csv'\n",
    "df = pd.read_csv(path, encoding_errors='ignore', parse_dates=['Date'], index_col='Date')\n",
    "pd.set_option('display.max_columns', None) # lets you scroll if your monitor isn't wide enough+\n",
    "\n",
    "# Dropping features\n",
    "df = df.drop(['Dew point temperature(C)', 'Holiday'], axis = 1)\n",
    "    \n",
    "# Converting Functioning Day to boolean\n",
    "df['Functioning Day'] = df['Functioning Day'].apply(lambda x: x == 'Yes' or x is True)\n",
    "    \n",
    "# One-hot Encoding Seasons\n",
    "df = pd.get_dummies(df, columns=['Seasons'], drop_first=True, prefix='', prefix_sep='')\n",
    "    \n",
    "# Converting booleans to integers\n",
    "df = df.astype({col: int for col in df.select_dtypes('bool').columns})\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # for scaling data\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "y = df['Rented Bike Count'].to_numpy() # target value\n",
    "X = df.drop('Rented Bike Count', axis=1) # taking out the target value\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, shuffle=True, random_state=1)\n",
    "\n",
    "# normalizing our target variable\n",
    "y_transformer = PowerTransformer('yeo-johnson')\n",
    "y_train = y_transformer.fit_transform(y_train.reshape(-1, 1)).ravel() # ravel flattens arrays to 1D, some models like it this way\n",
    "y_test = y_transformer.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "# changing snowfall and rainfall to binary features\n",
    "X_train['Rainfall_Binary'] = (X_train['Rainfall(mm)'] > 0).astype(int)\n",
    "X_test['Rainfall_Binary'] = (X_test['Rainfall(mm)'] > 0).astype(int)\n",
    "X_train['Snowfall_Binary'] = (X_train['Snowfall (cm)'] > 0).astype(int)\n",
    "X_test['Snowfall_Binary'] = (X_test['Snowfall (cm)'] > 0).astype(int)\n",
    "X_train = X_train.drop(['Rainfall(mm)', 'Snowfall (cm)'], axis=1)\n",
    "X_test = X_test.drop(['Rainfall(mm)', 'Snowfall (cm)'], axis=1)\n",
    "\n",
    "# Taking out our non-numerical values from the scaler\n",
    "scale_columns = ['Hour', 'Temperature(C)', 'Humidity(%)', 'Wind speed (m/s)', 'Visibility (10m)', 'Solar Radiation (MJ/m2)']\n",
    "no_scale = ['Functioning Day', 'Rainfall_Binary', 'Snowfall_Binary', 'Spring', 'Summer', 'Winter']\n",
    "\n",
    "# Separating numerical data from the rest\n",
    "no_scale_train = X_train[no_scale]\n",
    "no_scale_test = X_test[no_scale]\n",
    "train_to_scale = X_train[scale_columns]\n",
    "test_to_scale = X_test[scale_columns]\n",
    "\n",
    "# normalizing features skewed distributions (or at least attempting to)\n",
    "sun_transformer = PowerTransformer('yeo-johnson')\n",
    "train_to_scale.loc[:, 'Solar Radiation (MJ/m2)'] = sun_transformer.fit_transform(train_to_scale[['Solar Radiation (MJ/m2)']])\n",
    "test_to_scale.loc[:, 'Solar Radiation (MJ/m2)'] = sun_transformer.transform(test_to_scale[['Solar Radiation (MJ/m2)']])\n",
    "\n",
    "# standardizing all features\n",
    "scaler = StandardScaler()\n",
    "scaled_x_train = scaler.fit_transform(train_to_scale)\n",
    "scaled_x_test = scaler.transform(test_to_scale)\n",
    "\n",
    "# converting scaled data into dataframes to concat\n",
    "scaled_x_train = pd.DataFrame(scaled_x_train, index=X_train.index, columns=train_to_scale.columns)\n",
    "scaled_x_test = pd.DataFrame(scaled_x_test, index=X_test.index, columns=test_to_scale.columns)\n",
    "\n",
    "# concating the non-numerical data with the numerical\n",
    "X_train = pd.concat([scaled_x_train, no_scale_train], axis=1).to_numpy()\n",
    "X_test = pd.concat([scaled_x_test, no_scale_test], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up training and testing sets of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `xtrain` is the proportion of data we want to use for training. We set `train_size = 0.7` which means we want 70% of our data to be used for training\n",
    " - `xtest` is the proportion of data we want to test against the training proportion. Since 70% of the data was used for training, only 30% is used for testing\n",
    " - `ytrain` is the proportion (70%) of target values (bike count) that matches the corresponding data. Each row in `xtrain` has a corresponding bike count in `ytrain`\n",
    " - `ytest` is the proportion of target values we want to test against the training portion. Like before, each row in `xtest` has a corresponding bike count in `ytest`\n",
    "\n",
    "Pretty much we'll try to use `xtrain` and `ytrain` to predict what values will show up in `xtest` and `ytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA # dimension reduction\n",
    "\n",
    "pca = PCA(0.99)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "n_components = len(pca.components_)\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.barplot(x=[\"PC\" + str(i) for i in range(1, n_components + 1)], y=pca.explained_variance_ratio_)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Proportion of Variance in the Original Data')\n",
    "plt.title(f'{sum(pca.explained_variance_ratio_)* 100:.2f}% of variance explained with {n_components} components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, since PC1 and PC2 don't make up much of the variance, we have to use more components which make it impossible to visualize our data\n",
    "<br>That being said, it's easier to work with 8000x11 than 8000x14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.319778</td>\n",
       "      <td>1.634850</td>\n",
       "      <td>0.177172</td>\n",
       "      <td>0.574219</td>\n",
       "      <td>1.197747</td>\n",
       "      <td>0.035048</td>\n",
       "      <td>-0.441929</td>\n",
       "      <td>-0.513487</td>\n",
       "      <td>0.286158</td>\n",
       "      <td>0.225438</td>\n",
       "      <td>-0.120573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144898</td>\n",
       "      <td>1.273727</td>\n",
       "      <td>-0.980540</td>\n",
       "      <td>0.420522</td>\n",
       "      <td>0.043025</td>\n",
       "      <td>1.037696</td>\n",
       "      <td>0.185314</td>\n",
       "      <td>-0.235601</td>\n",
       "      <td>0.706841</td>\n",
       "      <td>0.289267</td>\n",
       "      <td>-0.023481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.507319</td>\n",
       "      <td>0.185355</td>\n",
       "      <td>-1.438461</td>\n",
       "      <td>-0.003032</td>\n",
       "      <td>-0.775526</td>\n",
       "      <td>0.505316</td>\n",
       "      <td>1.093062</td>\n",
       "      <td>0.199518</td>\n",
       "      <td>-0.229189</td>\n",
       "      <td>-0.497541</td>\n",
       "      <td>0.233358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.657003</td>\n",
       "      <td>-0.112323</td>\n",
       "      <td>1.141442</td>\n",
       "      <td>-0.129463</td>\n",
       "      <td>1.496104</td>\n",
       "      <td>-1.162994</td>\n",
       "      <td>-0.649341</td>\n",
       "      <td>-0.652583</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>-0.077838</td>\n",
       "      <td>0.351630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.778731</td>\n",
       "      <td>0.533182</td>\n",
       "      <td>0.648723</td>\n",
       "      <td>0.088687</td>\n",
       "      <td>1.176762</td>\n",
       "      <td>-0.782601</td>\n",
       "      <td>0.024933</td>\n",
       "      <td>-0.132832</td>\n",
       "      <td>0.646401</td>\n",
       "      <td>-0.366658</td>\n",
       "      <td>-0.192294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  1.319778  1.634850  0.177172  0.574219  1.197747  0.035048 -0.441929   \n",
       "1  0.144898  1.273727 -0.980540  0.420522  0.043025  1.037696  0.185314   \n",
       "2  0.507319  0.185355 -1.438461 -0.003032 -0.775526  0.505316  1.093062   \n",
       "3  1.657003 -0.112323  1.141442 -0.129463  1.496104 -1.162994 -0.649341   \n",
       "4  1.778731  0.533182  0.648723  0.088687  1.176762 -0.782601  0.024933   \n",
       "\n",
       "        PC8       PC9      PC10      PC11  \n",
       "0 -0.513487  0.286158  0.225438 -0.120573  \n",
       "1 -0.235601  0.706841  0.289267 -0.023481  \n",
       "2  0.199518 -0.229189 -0.497541  0.233358  \n",
       "3 -0.652583  0.508929 -0.077838  0.351630  \n",
       "4 -0.132832  0.646401 -0.366658 -0.192294  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094370</td>\n",
       "      <td>0.554295</td>\n",
       "      <td>-0.866272</td>\n",
       "      <td>0.298368</td>\n",
       "      <td>-0.353866</td>\n",
       "      <td>0.296275</td>\n",
       "      <td>-0.363227</td>\n",
       "      <td>0.870070</td>\n",
       "      <td>0.393558</td>\n",
       "      <td>0.146167</td>\n",
       "      <td>0.271632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.561807</td>\n",
       "      <td>1.023923</td>\n",
       "      <td>-0.808145</td>\n",
       "      <td>0.511466</td>\n",
       "      <td>-0.053537</td>\n",
       "      <td>0.431068</td>\n",
       "      <td>-0.416655</td>\n",
       "      <td>0.059763</td>\n",
       "      <td>0.485289</td>\n",
       "      <td>-0.452387</td>\n",
       "      <td>0.211460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.349448</td>\n",
       "      <td>0.700031</td>\n",
       "      <td>-0.112971</td>\n",
       "      <td>0.835891</td>\n",
       "      <td>-0.690431</td>\n",
       "      <td>-0.673962</td>\n",
       "      <td>-1.462074</td>\n",
       "      <td>0.585828</td>\n",
       "      <td>0.174904</td>\n",
       "      <td>0.162679</td>\n",
       "      <td>0.025893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.620917</td>\n",
       "      <td>-0.918206</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>0.094562</td>\n",
       "      <td>0.507789</td>\n",
       "      <td>0.599370</td>\n",
       "      <td>0.162920</td>\n",
       "      <td>0.450855</td>\n",
       "      <td>-0.451324</td>\n",
       "      <td>0.216446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.679991</td>\n",
       "      <td>-1.499702</td>\n",
       "      <td>-1.459200</td>\n",
       "      <td>-0.594231</td>\n",
       "      <td>-0.856789</td>\n",
       "      <td>0.251590</td>\n",
       "      <td>0.182467</td>\n",
       "      <td>-0.237463</td>\n",
       "      <td>0.384297</td>\n",
       "      <td>0.072653</td>\n",
       "      <td>0.302558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  0.094370  0.554295 -0.866272  0.298368 -0.353866  0.296275 -0.363227   \n",
       "1  0.561807  1.023923 -0.808145  0.511466 -0.053537  0.431068 -0.416655   \n",
       "2 -0.349448  0.700031 -0.112971  0.835891 -0.690431 -0.673962 -1.462074   \n",
       "3  0.966615  0.620917 -0.918206  0.080592  0.094562  0.507789  0.599370   \n",
       "4  0.679991 -1.499702 -1.459200 -0.594231 -0.856789  0.251590  0.182467   \n",
       "\n",
       "        PC8       PC9      PC10      PC11  \n",
       "0  0.870070  0.393558  0.146167  0.271632  \n",
       "1  0.059763  0.485289 -0.452387  0.211460  \n",
       "2  0.585828  0.174904  0.162679  0.025893  \n",
       "3  0.162920  0.450855 -0.451324  0.216446  \n",
       "4 -0.237463  0.384297  0.072653  0.302558  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_xtrain = pd.DataFrame(X_train_pca,  columns=[\"PC\" + str(i) for i in range(1, n_components + 1)])\n",
    "pca_xtest = pd.DataFrame(X_test_pca,  columns=[\"PC\" + str(i) for i in range(1, n_components + 1)])\n",
    "display(pca_xtrain.head())\n",
    "display(pca_xtest.head())\n",
    "# xtrain and xtest now have their respective pca counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import LinearSVR, NuSVR, SVR\n",
    "from sklearn.linear_model import ARDRegression, ElasticNet, ElasticNetCV, HuberRegressor, Lars, LarsCV, Lasso, LassoCV, LassoLarsCV, LassoLarsIC, LinearRegression\n",
    "from sklearn.linear_model import QuantileRegressor, RANSACRegressor, Ridge, RidgeCV, SGDRegressor, BayesianRidge\n",
    "from sklearn.linear_model import TheilSenRegressor, TweedieRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor,  HistGradientBoostingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 56.93%\n"
     ]
    }
   ],
   "source": [
    "linReg = LinearRegression()\n",
    "y_train_original = y_transformer.inverse_transform(y_train.reshape(-1,1))\n",
    "y_test_original = y_transformer.inverse_transform(y_test.reshape(-1,1))\n",
    "linReg.fit(X_train, y_train_original)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(linReg.score(X_test, y_test_original) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with 11 Components: 47.88%\n"
     ]
    }
   ],
   "source": [
    "pca_linReg = LinearRegression()\n",
    "y_train_original = y_transformer.inverse_transform(y_train.reshape(-1,1))\n",
    "y_test_original = y_transformer.inverse_transform(y_test.reshape(-1,1))\n",
    "pca_linReg.fit(pca_xtrain, y_train_original)\n",
    "print(\"Test Accuracy with {} Components: {:.2f}%\".format(n_components, pca_linReg.score(pca_xtest, y_test_original) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2_test</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>mse_train</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2_diff</th>\n",
       "      <th>mse_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.00</td>\n",
       "      <td>73240.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>270.630338</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>73240.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.97</td>\n",
       "      <td>78614.84</td>\n",
       "      <td>13482.94</td>\n",
       "      <td>280.383380</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>65131.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>83924.58</td>\n",
       "      <td>52347.79</td>\n",
       "      <td>289.697394</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>31576.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.95</td>\n",
       "      <td>85578.63</td>\n",
       "      <td>19085.53</td>\n",
       "      <td>292.538254</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>66493.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NuSVR</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>102714.80</td>\n",
       "      <td>100704.52</td>\n",
       "      <td>320.491498</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2010.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>102567.99</td>\n",
       "      <td>101195.19</td>\n",
       "      <td>320.262377</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1372.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>120117.05</td>\n",
       "      <td>112018.59</td>\n",
       "      <td>346.579067</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>8098.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.82</td>\n",
       "      <td>124413.33</td>\n",
       "      <td>75549.83</td>\n",
       "      <td>352.722738</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>48863.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.00</td>\n",
       "      <td>148455.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>385.298754</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>148455.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.00</td>\n",
       "      <td>179875.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>424.117319</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>179875.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>206809.49</td>\n",
       "      <td>211214.84</td>\n",
       "      <td>454.763114</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-4405.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>204877.57</td>\n",
       "      <td>209054.48</td>\n",
       "      <td>452.634035</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-4176.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KernelRidge</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223446.36</td>\n",
       "      <td>226786.25</td>\n",
       "      <td>472.701132</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3339.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARDRegression</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223214.16</td>\n",
       "      <td>226715.13</td>\n",
       "      <td>472.455458</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3500.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ElasticNetCV</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223429.79</td>\n",
       "      <td>226888.98</td>\n",
       "      <td>472.683605</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3459.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lars</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223447.42</td>\n",
       "      <td>226781.46</td>\n",
       "      <td>472.702253</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3334.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LarsCV</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223447.42</td>\n",
       "      <td>226781.46</td>\n",
       "      <td>472.702253</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3334.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223427.75</td>\n",
       "      <td>226866.02</td>\n",
       "      <td>472.681447</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3438.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LassoLarsCV</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223447.42</td>\n",
       "      <td>226781.46</td>\n",
       "      <td>472.702253</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3334.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LassoLarsIC</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223447.42</td>\n",
       "      <td>226781.46</td>\n",
       "      <td>472.702253</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3334.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223447.42</td>\n",
       "      <td>226781.46</td>\n",
       "      <td>472.702253</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3334.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223446.36</td>\n",
       "      <td>226786.25</td>\n",
       "      <td>472.701132</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3339.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223443.24</td>\n",
       "      <td>226834.55</td>\n",
       "      <td>472.697832</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3391.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>222540.10</td>\n",
       "      <td>225700.59</td>\n",
       "      <td>471.741561</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3160.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>223443.09</td>\n",
       "      <td>226830.61</td>\n",
       "      <td>472.697673</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3387.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RANSACRegressor</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>243613.35</td>\n",
       "      <td>245260.47</td>\n",
       "      <td>493.572031</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-1647.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TweedieRegressor</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>294639.38</td>\n",
       "      <td>303118.02</td>\n",
       "      <td>542.806945</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-8478.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>434945.40</td>\n",
       "      <td>447612.69</td>\n",
       "      <td>659.503904</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-12667.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>451796.40</td>\n",
       "      <td>463998.81</td>\n",
       "      <td>672.158017</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-12202.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QuantileRegressor</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>452217.16</td>\n",
       "      <td>464406.46</td>\n",
       "      <td>672.470936</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-12189.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TheilSenRegressor</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>1339768.03</td>\n",
       "      <td>861845.02</td>\n",
       "      <td>1157.483490</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>477923.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  r2_test  r2_train    mse_test  mse_train  \\\n",
       "26            ExtraTreesRegressor     0.82      1.00    73240.78       0.00   \n",
       "29          RandomForestRegressor     0.81      0.97    78614.84   13482.94   \n",
       "28  HistGradientBoostingRegressor     0.79      0.88    83924.58   52347.79   \n",
       "30                   XGBRegressor     0.79      0.95    85578.63   19085.53   \n",
       "5                           NuSVR     0.75      0.76   102714.80  100704.52   \n",
       "6                             SVR     0.75      0.76   102567.99  101195.19   \n",
       "27      GradientBoostingRegressor     0.70      0.73   120117.05  112018.59   \n",
       "2                      KNeighbors     0.69      0.82   124413.33   75549.83   \n",
       "0                    DecisionTree     0.63      1.00   148455.13       0.00   \n",
       "1                       ExtraTree     0.56      1.00   179875.50       0.00   \n",
       "4                       LinearSVR     0.49      0.50   206809.49  211214.84   \n",
       "10                 HuberRegressor     0.49      0.50   204877.57  209054.48   \n",
       "3                     KernelRidge     0.45      0.46   223446.36  226786.25   \n",
       "7                   ARDRegression     0.45      0.46   223214.16  226715.13   \n",
       "9                    ElasticNetCV     0.45      0.46   223429.79  226888.98   \n",
       "11                           Lars     0.45      0.46   223447.42  226781.46   \n",
       "12                         LarsCV     0.45      0.46   223447.42  226781.46   \n",
       "14                        LassoCV     0.45      0.46   223427.75  226866.02   \n",
       "15                    LassoLarsCV     0.45      0.46   223447.42  226781.46   \n",
       "16                    LassoLarsIC     0.45      0.46   223447.42  226781.46   \n",
       "17               LinearRegression     0.45      0.46   223447.42  226781.46   \n",
       "20                          Ridge     0.45      0.46   223446.36  226786.25   \n",
       "21                        RidgeCV     0.45      0.46   223443.24  226834.55   \n",
       "22                   SGDRegressor     0.45      0.46   222540.10  225700.59   \n",
       "23                  BayesianRidge     0.45      0.46   223443.09  226830.61   \n",
       "19                RANSACRegressor     0.40      0.42   243613.35  245260.47   \n",
       "25               TweedieRegressor     0.27      0.28   294639.38  303118.02   \n",
       "8                      ElasticNet    -0.07     -0.06   434945.40  447612.69   \n",
       "13                          Lasso    -0.11     -0.10   451796.40  463998.81   \n",
       "18              QuantileRegressor    -0.12     -0.10   452217.16  464406.46   \n",
       "24              TheilSenRegressor    -2.30     -1.05  1339768.03  861845.02   \n",
       "\n",
       "           rmse  r2_diff   mse_diff  \n",
       "26   270.630338    -0.18   73240.78  \n",
       "29   280.383380    -0.16   65131.90  \n",
       "28   289.697394    -0.09   31576.79  \n",
       "30   292.538254    -0.16   66493.10  \n",
       "5    320.491498    -0.01    2010.28  \n",
       "6    320.262377    -0.01    1372.80  \n",
       "27   346.579067    -0.03    8098.46  \n",
       "2    352.722738    -0.13   48863.50  \n",
       "0    385.298754    -0.37  148455.13  \n",
       "1    424.117319    -0.44  179875.50  \n",
       "4    454.763114    -0.01   -4405.35  \n",
       "10   452.634035    -0.01   -4176.91  \n",
       "3    472.701132    -0.01   -3339.89  \n",
       "7    472.455458    -0.01   -3500.97  \n",
       "9    472.683605    -0.01   -3459.19  \n",
       "11   472.702253    -0.01   -3334.04  \n",
       "12   472.702253    -0.01   -3334.04  \n",
       "14   472.681447    -0.01   -3438.27  \n",
       "15   472.702253    -0.01   -3334.04  \n",
       "16   472.702253    -0.01   -3334.04  \n",
       "17   472.702253    -0.01   -3334.04  \n",
       "20   472.701132    -0.01   -3339.89  \n",
       "21   472.697832    -0.01   -3391.31  \n",
       "22   471.741561    -0.01   -3160.49  \n",
       "23   472.697673    -0.01   -3387.52  \n",
       "19   493.572031    -0.02   -1647.12  \n",
       "25   542.806945    -0.01   -8478.64  \n",
       "8    659.503904    -0.01  -12667.29  \n",
       "13   672.158017    -0.01  -12202.41  \n",
       "18   672.470936    -0.02  -12189.30  \n",
       "24  1157.483490    -1.25  477923.01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_model = {\n",
    "    'DecisionTree' : DecisionTreeRegressor(),\n",
    "    'ExtraTree' : ExtraTreeRegressor(),\n",
    "    'KNeighbors' : KNeighborsRegressor(),\n",
    "    'KernelRidge' : KernelRidge(),\n",
    "    'LinearSVR' : LinearSVR(),\n",
    "    'NuSVR' : NuSVR(),\n",
    "    'SVR' : SVR(),\n",
    "    'ARDRegression' : ARDRegression(),\n",
    "    'ElasticNet' : ElasticNet(),\n",
    "    'ElasticNetCV' : ElasticNetCV(),\n",
    "    'HuberRegressor' : HuberRegressor(),\n",
    "    'Lars' : Lars(),\n",
    "    'LarsCV' : LarsCV(),\n",
    "    'Lasso' : Lasso(),\n",
    "    'LassoCV' : LassoCV(),\n",
    "    'LassoLarsCV' : LassoLarsCV(),\n",
    "    'LassoLarsIC' : LassoLarsIC(),\n",
    "    'LinearRegression' : LinearRegression(),\n",
    "    'QuantileRegressor' : QuantileRegressor(),\n",
    "    'RANSACRegressor' : RANSACRegressor(),\n",
    "    'Ridge' : Ridge(),\n",
    "    'RidgeCV' : RidgeCV(),\n",
    "    'SGDRegressor' : SGDRegressor(),\n",
    "    'BayesianRidge' : BayesianRidge(),\n",
    "    'TheilSenRegressor' : TheilSenRegressor(),\n",
    "    'TweedieRegressor' : TweedieRegressor(),\n",
    "    'ExtraTreesRegressor' : ExtraTreesRegressor(),\n",
    "    'GradientBoostingRegressor' : GradientBoostingRegressor(),\n",
    "    'HistGradientBoostingRegressor' : HistGradientBoostingRegressor(),\n",
    "    'RandomForestRegressor' : RandomForestRegressor(),\n",
    "    'XGBRegressor' : XGBRegressor()\n",
    "    }\n",
    "\n",
    "screening = [] # our output\n",
    "\n",
    "for name, model in all_model.items():\n",
    "    print(name) # for debugging\n",
    "\n",
    "    reg = model.fit(pca_xtrain, y_train)\n",
    "\n",
    "    train_pred = reg.predict(pca_xtrain)\n",
    "    test_pred = reg.predict(pca_xtest)\n",
    "\n",
    "    pred_train_original = y_transformer.inverse_transform(train_pred.reshape(-1,1))\n",
    "    pred_test_original = y_transformer.inverse_transform(test_pred.reshape(-1,1))\n",
    "    y_train_original = y_transformer.inverse_transform(y_train.reshape(-1,1))\n",
    "    y_test_original = y_transformer.inverse_transform(y_test.reshape(-1,1))\n",
    "\n",
    "    r2_train = round(r2_score(y_train_original, pred_train_original), 2)\n",
    "    r2_test = round(r2_score(y_test_original, pred_test_original), 2)\n",
    "    mse_train = round(mean_squared_error(y_train_original, pred_train_original), 2)\n",
    "    mse_test = round(mean_squared_error(y_test_original, pred_test_original), 2)\n",
    "    rmse = np.sqrt(mse_test)\n",
    "    screening.append([name, r2_test, r2_train, mse_test, mse_train, rmse])\n",
    "\n",
    "# converting output to a dataframe and adding column names\n",
    "screening_df = pd.DataFrame(screening, columns=('model', 'r2_test', 'r2_train', 'mse_test', 'mse_train', 'rmse'))\n",
    "\n",
    "# makes it easier to find overfitting, should be positive\n",
    "screening_df['r2_diff'] = screening_df['r2_test'] - screening_df['r2_train']\n",
    "\n",
    "# makes it easier to find overfitting, should be negative\n",
    "screening_df['mse_diff'] = screening_df['mse_test'] - screening_df['mse_train']\n",
    "\n",
    "clear_output(True) # clean up output\n",
    "display(screening_df.sort_values(['r2_test', 'r2_diff'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "If you look at our model file, I perform this exact same \"everything under the sun\" test on our data **without** PCA\n",
    "<br>With PCA, everything just performs worse so there's no point in doing it\n",
    "<br>The tradeoff between lower dimensionality and worse performance isn't worth the trouble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
